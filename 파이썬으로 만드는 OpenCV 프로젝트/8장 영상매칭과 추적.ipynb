{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "ffff8000800080008000813fc1ffc1ffc07fc3ffc7ffc7ff87ff87ff87ffc7ff\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "#영상 읽어서 그레이 스케일로 변환\n",
    "img = cv2.imread('./img/pistol.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 8x8 크기로 축소 ---①\n",
    "gray = cv2.resize(gray, (16,16))\n",
    "# 영상의 평균값 구하기 ---②\n",
    "avg = gray.mean()\n",
    "# 평균값을 기준으로 0과 1로 변환 ---③\n",
    "bin = 1 * (gray > avg)\n",
    "print(bin)\n",
    "\n",
    "# 2진수 문자열을 16진수 문자열로 변환 ---④\n",
    "dhash = []\n",
    "for row in bin.tolist():\n",
    "    s = ''.join([str(i) for i in row])\n",
    "    dhash.append('%02x'%(int(s,2)))\n",
    "dhash = ''.join(dhash)\n",
    "print(dhash)\n",
    "\n",
    "cv2.namedWindow('pistol', cv2.WINDOW_GUI_NORMAL)\n",
    "cv2.imshow('pistol', img)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2.TM_CCOEFF_NORMED -0.1780252307653427 0.5131933093070984 (42, 0) (208, 43)\n",
      "cv2.TM_CCORR_NORMED 0.827332615852356 0.9238022565841675 (85, 6) (208, 43)\n",
      "cv2.TM_SQDIFF_NORMED 0.17028295993804932 0.36860838532447815 (208, 43) (86, 7)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 입력이미지와 템플릿 이미지 읽기\n",
    "img = cv2.imread('./img/figures.jpg')\n",
    "template = cv2.imread('./img/taekwonv1.jpg')\n",
    "th, tw = template.shape[:2]\n",
    "cv2.imshow('template', template)\n",
    "\n",
    "# 3가지 매칭 메서드 순회\n",
    "methods = ['cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR_NORMED', \\\n",
    "                                     'cv2.TM_SQDIFF_NORMED']\n",
    "for i, method_name in enumerate(methods):\n",
    "    img_draw = img.copy()\n",
    "    method = eval(method_name)\n",
    "    # 템플릿 매칭   ---①\n",
    "    res = cv2.matchTemplate(img, template, method)\n",
    "    # 최대, 최소값과 그 좌표 구하기 ---②\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    print(method_name, min_val, max_val, min_loc, max_loc)\n",
    "\n",
    "    # TM_SQDIFF의 경우 최소값이 좋은 매칭, 나머지는 그 반대 ---③\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "        match_val = min_val\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "        match_val = max_val\n",
    "    # 매칭 좌표 구해서 사각형 표시   ---④      \n",
    "    bottom_right = (top_left[0] + tw, top_left[1] + th)\n",
    "    cv2.rectangle(img_draw, top_left, bottom_right, (0,0,255),2)\n",
    "    # 매칭 포인트 표시 ---⑤\n",
    "    cv2.putText(img_draw, str(match_val), top_left, \\\n",
    "                cv2.FONT_HERSHEY_PLAIN, 2,(0,255,0), 1, cv2.LINE_AA)\n",
    "    cv2.imshow(method_name, img_draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./img/house.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 해리스 코너 검출 ---①\n",
    "corner = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "# 변화량 결과의 최대값 10% 이상의 좌표 구하기 ---②\n",
    "coord = np.where(corner > 0.1* corner.max())\n",
    "coord = np.stack((coord[1], coord[0]), axis=-1)\n",
    "\n",
    "# 코너 좌표에 동그리미 그리기 ---③\n",
    "for x, y in coord:\n",
    "    cv2.circle(img, (x,y), 5, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "# 변화량을 영상으로 표현하기 위해서 0~255로 정규화 ---④\n",
    "corner_norm = cv2.normalize(corner, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "# 화면에 출력\n",
    "corner_norm = cv2.cvtColor(corner_norm, cv2.COLOR_GRAY2BGR)\n",
    "merged = np.hstack((corner_norm, img))\n",
    "cv2.imshow('Harris Corner', merged)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./img/house.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 시-토마스의 코너 검출 메서드\n",
    "corners = cv2.goodFeaturesToTrack(gray, 80, 0.01, 10)\n",
    "# 실수 좌표를 정수 좌표로 변환\n",
    "corners = np.int32(corners)\n",
    "\n",
    "# 좌표에 동그라미 표시\n",
    "for corner in corners:\n",
    "    x, y = corner[0]\n",
    "    cv2.circle(img, (x, y), 5, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('Corners', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"./img/house.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Good feature to trac 검출기 생성 ---①\n",
    "gftt = cv2.GFTTDetector_create() \n",
    "# 키 포인트 검출 ---②\n",
    "keypoints = gftt.detect(gray, None)\n",
    "# 키 포인트 그리기 ---③\n",
    "img_draw = cv2.drawKeypoints(img, keypoints, None)\n",
    "\n",
    "# 결과 출력 ---④\n",
    "cv2.imshow('GFTTDectector', img_draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./img/house.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# FASt 특징 검출기 생성 ---①\n",
    "fast = cv2.FastFeatureDetector_create(50)\n",
    "# 키 포인트 검출 ---②\n",
    "keypoints = fast.detect(gray, None)\n",
    "# 키 포인트 그리기 ---③\n",
    "img = cv2.drawKeypoints(img, keypoints, None)\n",
    "# 결과 출력 ---④\n",
    "cv2.imshow('FAST', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"./img/house.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# SimpleBlobDetector 생성 ---①\n",
    "detector = cv2.SimpleBlobDetector_create()\n",
    "# 키 포인트 검출 ---②\n",
    "keypoints = detector.detect(gray)\n",
    "# 키 포인트를 빨간색으로 표시 ---③\n",
    "img = cv2.drawKeypoints(img, keypoints, None, (0,0,255),\\\n",
    "                flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    " \n",
    "cv2.imshow(\"Blob\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'sift'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9a1cbd6d6d7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# SIFT 추출기 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msift\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# 키 포인트 검출과 서술자 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mkeypoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescriptor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'sift'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./img/house.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# SIFT 추출기 생성\n",
    "sift = cv2.()\n",
    "# 키 포인트 검출과 서술자 계산\n",
    "keypoints, descriptor = sift.detectAndCompute(gray, None)\n",
    "print('keypoint:',len(keypoints), 'descriptor:', descriptor.shape)\n",
    "print(descriptor)\n",
    "\n",
    "# 키 포인트 그리기\n",
    "img_draw = cv2.drawKeypoints(img, keypoints, None, \\\n",
    "                flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "# 결과 출력\n",
    "cv2.imshow('SIFT', img_draw)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./img/house.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ORB 추출기 생성\n",
    "orb = cv2.ORB_create()\n",
    "# 키 포인트 검출과 서술자 계산\n",
    "keypoints, descriptor = orb.detectAndCompute(img, None)\n",
    "# 키 포인트 그리기\n",
    "img_draw = cv2.drawKeypoints(img, keypoints, None, \\\n",
    "             flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "# 결과 출력\n",
    "cv2.imshow('ORB', img_draw)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('./img/taekwonv1.jpg')\n",
    "img2 = cv2.imread('./img/figures.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# SIFT 서술자 추출기 생성 ---①\n",
    "detector = cv2.ORB_create()\n",
    "# 각 영상에 대해 키 포인트와 서술자 추출 ---②\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "\n",
    "# BFMatcher 생성, Hamming 거리, 상호 체크 ---③\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "# 매칭 계산 ---④\n",
    "matches = matcher.match(desc1, desc2)\n",
    "# 매칭 결과 그리기 ---⑤\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                     flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "cv2.imshow('BFMatcher + ORB', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv_contrib\\modules\\xfeatures2d\\src\\surf.cpp:1029: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'cv::xfeatures2d::SURF::create'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a061b8aafb21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# SURF 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSURF_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# 키 포인트와 서술자 추출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mkp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv_contrib\\modules\\xfeatures2d\\src\\surf.cpp:1029: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'cv::xfeatures2d::SURF::create'\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('./img/taekwonv1.jpg')\n",
    "img2 = cv2.imread('./img/figures.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# SURF 생성\n",
    "detector = cv2.xfeatures2d.SURF_create()\n",
    "# 키 포인트와 서술자 추출\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "\n",
    "# 인덱스 파라미터와 검색 파라미터 설정 ---①\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "# Flann 매처 생성 ---③\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "# 매칭 계산 ---④\n",
    "matches = matcher.match(desc1, desc2)\n",
    "# 매칭 그리기\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "cv2.imshow('Flann + SURF', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('./img/taekwonv1.jpg')\n",
    "img2 = cv2.imread('./img/figures.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ORB 추출기 생성\n",
    "detector = cv2.ORB_create()\n",
    "# 키 포인트와 서술자 추출\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "\n",
    "# 인덱스 파라미터 설정 ---①\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                   table_number = 6,\n",
    "                   key_size = 12,\n",
    "                   multi_probe_level = 1)\n",
    "# 검색 파라미터 설정 ---②\n",
    "search_params=dict(checks=32)\n",
    "# Flann 매처 생성 ---③\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "# 매칭 계산 ---④\n",
    "matches = matcher.match(desc1, desc2)\n",
    "# 매칭 그리기\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "            flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "# 결과 출력            \n",
    "cv2.imshow('Flann + ORB', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches:18/127, min:24.00, max:78.00, thresh:34.80\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('./img/taekwonv1.jpg')\n",
    "img2 = cv2.imread('./img/figures.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ORB로 서술자 추출 ---①\n",
    "detector = cv2.ORB_create()\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "# BF-Hamming으로 매칭 ---②\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = matcher.match(desc1, desc2)\n",
    "\n",
    "# 매칭 결과를 거리기준 오름차순으로 정렬 ---③\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "# 최소 거리 값과 최대 거리 값 확보 ---④\n",
    "min_dist, max_dist = matches[0].distance, matches[-1].distance\n",
    "# 최소 거리의 15% 지점을 임계점으로 설정 ---⑤\n",
    "ratio = 0.2\n",
    "good_thresh = (max_dist - min_dist) * ratio + min_dist\n",
    "# 임계점 보다 작은 매칭점만 좋은 매칭점으로 분류 ---⑥\n",
    "good_matches = [m for m in matches if m.distance < good_thresh]\n",
    "print('matches:%d/%d, min:%.2f, max:%.2f, thresh:%.2f' \\\n",
    "        %(len(good_matches),len(matches), min_dist, max_dist, good_thresh))\n",
    "# 좋은 매칭점만 그리기 ---⑦\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, \\\n",
    "                flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "# 결과 출력\n",
    "cv2.imshow('Good Match', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches:23/500\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('./img/taekwonv1.jpg')\n",
    "img2 = cv2.imread('./img/figures.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ORB로 서술자 추출 ---①\n",
    "detector = cv2.ORB_create()\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "# BF-Hamming 생성 ---②\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING2)\n",
    "# knnMatch, k=2 ---③\n",
    "matches = matcher.knnMatch(desc1, desc2, 2)\n",
    "\n",
    "# 첫번재 이웃의 거리가 두 번째 이웃 거리의 75% 이내인 것만 추출---⑤\n",
    "ratio = 0.75\n",
    "good_matches = [first for first,second in matches \\\n",
    "                    if first.distance < second.distance * ratio]\n",
    "print('matches:%d/%d' %(len(good_matches),len(matches)))\n",
    "\n",
    "# 좋은 매칭만 그리기\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, \\\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "# 결과 출력                    \n",
    "cv2.imshow('Matching', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good matches:23/500\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('./img/taekwonv1.jpg')\n",
    "img2 = cv2.imread('./img/figures.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ORB, BF-Hamming 로 knnMatch  ---①\n",
    "detector = cv2.ORB_create()\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING2)\n",
    "matches = matcher.knnMatch(desc1, desc2, 2)\n",
    "\n",
    "# 이웃 거리의 75%로 좋은 매칭점 추출---②\n",
    "ratio = 0.75\n",
    "good_matches = [first for first,second in matches \\\n",
    "                    if first.distance < second.distance * ratio]\n",
    "print('good matches:%d/%d' %(len(good_matches),len(matches)))\n",
    "\n",
    "# 좋은 매칭점의 queryIdx로 원본 영상의 좌표 구하기 ---③\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ])\n",
    "# 좋은 매칭점의 trainIdx로 대상 영상의 좌표 구하기 ---④\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ])\n",
    "# 원근 변환 행렬 구하기 ---⑤\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts)\n",
    "# 원본 영상 크기로 변환 영역 좌표 생성 ---⑥\n",
    "h,w, = img1.shape[:2]\n",
    "pts = np.float32([ [[0,0]],[[0,h-1]],[[w-1,h-1]],[[w-1,0]] ])\n",
    "# 원본 영상 좌표를 원근 변환  ---⑦\n",
    "dst = cv2.perspectiveTransform(pts,mtrx)\n",
    "# 변환 좌표 영역을 대상 영상에 그리기 ---⑧\n",
    "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "# 좋은 매칭 그려서 출력 ---⑨\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, \\\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imshow('Matching Homography', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 25/135(0.19%)\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('./img/taekwonv1.jpg')\n",
    "img2 = cv2.imread('./img/figures2.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ORB, BF-Hamming 로 knnMatch  ---①\n",
    "detector = cv2.ORB_create()\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = matcher.match(desc1, desc2)\n",
    "\n",
    "# 매칭 결과를 거리기준 오름차순으로 정렬 ---③\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "# 모든 매칭점 그리기 ---④\n",
    "res1 = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# 매칭점으로 원근 변환 및 영역 표시 ---⑤\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in matches ])\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in matches ])\n",
    "# RANSAC으로 변환 행렬 근사 계산 ---⑥\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "h,w = img1.shape[:2]\n",
    "pts = np.float32([ [[0,0]],[[0,h-1]],[[w-1,h-1]],[[w-1,0]] ])\n",
    "dst = cv2.perspectiveTransform(pts,mtrx)\n",
    "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "# 정상치 매칭만 그리기 ---⑦\n",
    "matchesMask = mask.ravel().tolist()\n",
    "res2 = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                    matchesMask = matchesMask,\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "# 모든 매칭점과 정상치 비율 ---⑧\n",
    "accuracy=float(mask.sum()) / mask.size\n",
    "print(\"accuracy: %d/%d(%.2f%%)\"% (mask.sum(), mask.size, accuracy))\n",
    "\n",
    "# 결과 출력                    \n",
    "cv2.imshow('Matching-All', res1)\n",
    "cv2.imshow('Matching-Inlier ', res2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, cv2\n",
    "\n",
    "cap = cv2.VideoCapture('./img/walking.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "# 배경 제거 객체 생성 --- ①\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # 배경 제거 마스크 계산 --- ②\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('bgsub',fgmask)\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, cv2\n",
    "\n",
    "cap = cv2.VideoCapture('./img/walking.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "# 배경 제거 객체 생성 --- ①\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # 배경 제거 마스크 계산 --- ②\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('bgsub',fgmask)\n",
    "    if cv2.waitKey(delay) & 0xff == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, cv2\n",
    "\n",
    "cap = cv2.VideoCapture('./img/walking.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "# 추적 경로를 그리기 위한 랜덤 색상\n",
    "color = np.random.randint(0,255,(200,3))\n",
    "lines = None  #추적 선을 그릴 이미지 저장 변수\n",
    "prevImg = None  # 이전 프레임 저장 변수\n",
    "# calcOpticalFlowPyrLK 중지 요건 설정\n",
    "termcriteria =  (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    img_draw = frame.copy()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # 최초 프레임 경우\n",
    "    if prevImg is None:\n",
    "        prevImg = gray\n",
    "        # 추적선 그릴 이미지를 프레임 크기에 맞게 생성\n",
    "        lines = np.zeros_like(frame)\n",
    "        # 추적 시작을 위한 코너 검출  ---①\n",
    "        prevPt = cv2.goodFeaturesToTrack(prevImg, 200, 0.01, 10)\n",
    "    else:\n",
    "        nextImg = gray\n",
    "        # 옵티컬 플로우로 다음 프레임의 코너점  찾기 ---②\n",
    "        nextPt, status, err = cv2.calcOpticalFlowPyrLK(prevImg, nextImg, \\\n",
    "                                        prevPt, None, criteria=termcriteria)\n",
    "        # 대응점이 있는 코너, 움직인 코너 선별 ---③\n",
    "        prevMv = prevPt[status==1]\n",
    "        nextMv = nextPt[status==1]\n",
    "        for i,(p, n) in enumerate(zip(prevMv, nextMv)):\n",
    "            px,py = p.ravel()\n",
    "            nx,ny = n.ravel()\n",
    "            # 이전 코너와 새로운 코너에 선그리기 ---④\n",
    "            cv2.line(lines, (px, py), (nx,ny), color[i].tolist(), 2)\n",
    "            # 새로운 코너에 점 그리기\n",
    "            cv2.circle(img_draw, (nx,ny), 2, color[i].tolist(), -1)\n",
    "        # 누적된 추적 선을 출력 이미지에 합성 ---⑤\n",
    "        img_draw = cv2.add(img_draw, lines)\n",
    "        # 다음 프레임을 위한 프레임과 코너점 이월\n",
    "        prevImg = nextImg\n",
    "        prevPt = nextMv.reshape(-1,1,2)\n",
    "\n",
    "    cv2.imshow('OpticalFlow-LK', img_draw)\n",
    "    key = cv2.waitKey(delay)\n",
    "    if key == 27 : # Esc:종료\n",
    "        break\n",
    "    elif key == 8: # Backspace:추적 이력 지우기\n",
    "        prevImg = None\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
